{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f458b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4807c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I love reading my books on this, and the Alexa...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's good to have this box if you like to watc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It is ok to be a \"android\" tablet with such a ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The battery on this device cannot handle true ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I bought 2 of these on Black Friday and these ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       reviews.text  \\\n",
       "0           0  I love reading my books on this, and the Alexa...   \n",
       "1           1  It's good to have this box if you like to watc...   \n",
       "2           2  It is ok to be a \"android\" tablet with such a ...   \n",
       "3           3  The battery on this device cannot handle true ...   \n",
       "4           4  I bought 2 of these on Black Friday and these ...   \n",
       "\n",
       "   reviews.doRecommend  \n",
       "0                 True  \n",
       "1                 True  \n",
       "2                False  \n",
       "3                 True  \n",
       "4                False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"modified_data.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5631aea6",
   "metadata": {},
   "source": [
    "# Preparing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a1cdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     11170\n",
       "False     1384\n",
       "Name: reviews.doRecommend, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"reviews.doRecommend\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c41e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake(dorecommend):\n",
    "    if dorecommend==True:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae76bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[\"reviews.text\"]\n",
    "y=data[\"reviews.doRecommend\"].apply(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587b6bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11170\n",
       "1     1384\n",
       "Name: reviews.doRecommend, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d6158",
   "metadata": {},
   "source": [
    "# Preparing Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c3db3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.4,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219342ac",
   "metadata": {},
   "source": [
    "# Feature Extraction of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "badd1343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ranti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords') \n",
    "\n",
    "def remove_punctuation_marks(text) :\n",
    "    punctuation_marks = dict((ord(punctuation_mark), None) for punctuation_mark in string.punctuation)\n",
    "    return text.translate(punctuation_marks)\n",
    "\n",
    "def get_lemmatized_tokens(text) :\n",
    "    normalized_tokens = nltk.word_tokenize(remove_punctuation_marks(text.lower()))\n",
    "    return [nltk.stem.WordNetLemmatizer().lemmatize(normalized_token) for normalized_token in normalized_tokens]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7499082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 7389)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_transformer = TfidfVectorizer(tokenizer = get_lemmatized_tokens, lowercase=True, stop_words = stopwords.words('english'))\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train)\n",
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d8945",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54db2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac06f8e",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef909a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 tokenizer=<function get_lemmatized_tokens at 0x000000000B9E03A0>)),\n",
       "                ('clf_nominalNB', MultinomialNB())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "tfidf_multiNB_pipe = Pipeline([ \n",
    "                             (\"tfidf\", tfidf_transformer),\n",
    "                             (\"clf_nominalNB\", MultinomialNB())])\n",
    "tfidf_multiNB_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b6a4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8870967741935484"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "prediction = tfidf_multiNB_pipe.predict(x_test)\n",
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f66b88cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4454\n",
      "           1       1.00      0.00      0.00       568\n",
      "\n",
      "    accuracy                           0.89      5022\n",
      "   macro avg       0.94      0.50      0.47      5022\n",
      "weighted avg       0.90      0.89      0.83      5022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, \n",
    "                            prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7635ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5021\n",
       "1       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prediction).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8d486",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f973ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093986459577857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_svm_pipe = Pipeline([(\"vect\", tfidf_transformer), \n",
    "                            (\"clf_svc\", LinearSVC())])\n",
    "clf_svm_pipe.fit(x_train, y_train)\n",
    "                            \n",
    "prediction=clf_svm_pipe.predict(x_test)                 \n",
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8ad2e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      4454\n",
      "           1       0.67      0.39      0.49       568\n",
      "\n",
      "    accuracy                           0.91      5022\n",
      "   macro avg       0.80      0.68      0.72      5022\n",
      "weighted avg       0.90      0.91      0.90      5022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, \n",
    "                            prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ba5d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4693\n",
       "1     329\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prediction).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ffd665",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fff5782e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026284348864994"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_logReg_pipe = Pipeline([(\"vect\", tfidf_transformer), \n",
    "                            (\"clf_logReg\", LogisticRegression())])\n",
    "clf_logReg_pipe.fit(x_train, y_train)\n",
    "                            \n",
    "prediction=clf_logReg_pipe.predict(x_test)                 \n",
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9435671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4454\n",
      "           1       0.83      0.17      0.29       568\n",
      "\n",
      "    accuracy                           0.90      5022\n",
      "   macro avg       0.87      0.58      0.62      5022\n",
      "weighted avg       0.90      0.90      0.87      5022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, \n",
    "                            prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dd735f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4903\n",
       "1     119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prediction).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82ab60",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27d3bc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665870171246516"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "clf_decision_pipe = Pipeline([(\"vect\", tfidf_transformer), \n",
    "                            (\"clf_dec\", DecisionTreeClassifier())])\n",
    "clf_decision_pipe.fit(x_train, y_train)\n",
    "                            \n",
    "prediction=clf_decision_pipe.predict(x_test)                 \n",
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9773c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      4454\n",
      "           1       0.40      0.36      0.38       568\n",
      "\n",
      "    accuracy                           0.87      5022\n",
      "   macro avg       0.66      0.65      0.65      5022\n",
      "weighted avg       0.86      0.87      0.86      5022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, \n",
    "                            prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbbae21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4506\n",
       "1     516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prediction).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0554b",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55bcd48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928713659896456"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_random_pipe = Pipeline([(\"vect\", tfidf_transformer), \n",
    "                            (\"clf_ran\", RandomForestClassifier())])\n",
    "clf_random_pipe.fit(x_train, y_train)\n",
    "                            \n",
    "prediction=clf_random_pipe.predict(x_test)                 \n",
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6427c37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4454\n",
      "           1       0.73      0.08      0.15       568\n",
      "\n",
      "    accuracy                           0.89      5022\n",
      "   macro avg       0.81      0.54      0.55      5022\n",
      "weighted avg       0.88      0.89      0.85      5022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, \n",
    "                            prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "643cd468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4958\n",
       "1      64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prediction).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a915c",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30686abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 tokenizer=<function get_lemmatized_tokens at 0x000000000B9E03A0>)),\n",
       "                ('clf_dec', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([(\"vect\", tfidf_transformer), \n",
    "                            (\"clf_dec\", DecisionTreeClassifier())])\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f49e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "902ee1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fake.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"fake.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d443f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
